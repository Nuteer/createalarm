{
  "version": "2",
  "toolVersion": "1.47.0",
  "snippets": {
    "5cb22137d1284090e6e0981b178df402271fcee8bbd8ed24b81398f4d34a5ecf": {
      "translations": {
        "python": {
          "source": "bucket = s3.Bucket(self, \"Bucket\")\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket)]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "Bucket bucket = new Bucket(this, \"Bucket\");\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket) }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket = new Bucket(this, \"Bucket\");\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(new S3Bucket(bucket)))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "const bucket = new s3.Bucket(this, 'Bucket');\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket)],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 46
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-s3.Bucket",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\nconst bucket = new s3.Bucket(this, 'Bucket');\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket)],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 2,
        "75": 9,
        "104": 2,
        "192": 1,
        "193": 1,
        "194": 3,
        "197": 3,
        "225": 1,
        "226": 1,
        "242": 1,
        "243": 1,
        "281": 1
      },
      "fqnsFingerprint": "fbf9af1546928a3d8cb20ad5b8f0f433daad0d22908e2621682abc6f0afbfaa9"
    },
    "1ec4adc73f7ac49ce3b5b42c40d3a04fef1f42f7cd236c852cd365a1ee1e7883": {
      "translations": {
        "python": {
          "source": "# destination is of type IDestination\n\nsource_stream = kinesis.Stream(self, \"Source Stream\")\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    source_stream=source_stream,\n    destinations=[destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "IDestination destination;\n\nStream sourceStream = new Stream(this, \"Source Stream\");\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    SourceStream = sourceStream,\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "IDestination destination;\n\nStream sourceStream = new Stream(this, \"Source Stream\");\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .sourceStream(sourceStream)\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "declare const destination: firehose.IDestination;\nconst sourceStream = new kinesis.Stream(this, 'Source Stream');\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  sourceStream: sourceStream,\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 74
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesis.IStream",
        "@aws-cdk/aws-kinesis.Stream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const destination: firehose.IDestination;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst sourceStream = new kinesis.Stream(this, 'Source Stream');\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  sourceStream: sourceStream,\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 2,
        "75": 12,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 1,
        "194": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "90d8ed2481050dff61299d1fbe0025a444fede73abb1fe679e4ceaff8c43f20b"
    },
    "e54b836c20a4cd5b233d4e4de6c244f328eb6014b970d6935b59c0c68ee5ad85": {
      "translations": {
        "python": {
          "source": "# bucket is of type Bucket\n\ns3_destination = destinations.S3Bucket(bucket)\n\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "Bucket bucket;\n\nS3Bucket s3Destination = new S3Bucket(bucket);\n\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n\nS3Bucket s3Destination = new S3Bucket(bucket);\n\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "declare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket);\n\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 111
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst s3Destination = new destinations.S3Bucket(bucket);\n\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "75": 11,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 1,
        "194": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 1,
        "290": 1
      },
      "fqnsFingerprint": "c2348b96e9e82c63e62aaf0585714a91d030bac22ac3354e0535c69beec85eaf"
    },
    "ecfe0d7a66f8077bdb0b151144d48028799c315b553863ef076c2a7991d21290": {
      "translations": {
        "python": {
          "source": "# bucket is of type Bucket\n\ns3_destination = destinations.S3Bucket(bucket,\n    data_output_prefix=\"myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}\",\n    error_output_prefix=\"myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}\"\n)",
          "version": "1"
        },
        "csharp": {
          "source": "Bucket bucket;\n\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    DataOutputPrefix = \"myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}\",\n    ErrorOutputPrefix = \"myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}\"\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .dataOutputPrefix(\"myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}\")\n        .errorOutputPrefix(\"myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}\")\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "declare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  dataOutputPrefix: 'myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}',\n  errorOutputPrefix: 'myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}',\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 124
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  dataOutputPrefix: 'myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}',\n  errorOutputPrefix: 'myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}',\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 2,
        "75": 9,
        "130": 1,
        "153": 1,
        "169": 1,
        "193": 1,
        "194": 1,
        "197": 1,
        "225": 2,
        "242": 2,
        "243": 2,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "2061a4174dfd14db374b779212a398d72bf29f32eb1334fad0a51360442ee00b"
    },
    "ccfe931718f827ba8834e4195dd1be88565e1fe09037d053055b5aecb8698366": {
      "translations": {
        "python": {
          "source": "# destination is of type IDestination\n# SSE with an customer-managed CMK that is explicitly specified\n# key is of type Key\n\n\n# SSE with an AWS-owned CMK\nfirehose.DeliveryStream(self, \"Delivery Stream AWS Owned\",\n    encryption=firehose.StreamEncryption.AWS_OWNED,\n    destinations=[destination]\n)\n# SSE with an customer-managed CMK that is created automatically by the CDK\nfirehose.DeliveryStream(self, \"Delivery Stream Implicit Customer Managed\",\n    encryption=firehose.StreamEncryption.CUSTOMER_MANAGED,\n    destinations=[destination]\n)\nfirehose.DeliveryStream(self, \"Delivery Stream Explicit Customer Managed\",\n    encryption_key=key,\n    destinations=[destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "IDestination destination;\n// SSE with an customer-managed CMK that is explicitly specified\nKey key;\n\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nnew DeliveryStream(this, \"Delivery Stream AWS Owned\", new DeliveryStreamProps {\n    Encryption = StreamEncryption.AWS_OWNED,\n    Destinations = new [] { destination }\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew DeliveryStream(this, \"Delivery Stream Implicit Customer Managed\", new DeliveryStreamProps {\n    Encryption = StreamEncryption.CUSTOMER_MANAGED,\n    Destinations = new [] { destination }\n});\nnew DeliveryStream(this, \"Delivery Stream Explicit Customer Managed\", new DeliveryStreamProps {\n    EncryptionKey = key,\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "IDestination destination;\n// SSE with an customer-managed CMK that is explicitly specified\nKey key;\n\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nDeliveryStream.Builder.create(this, \"Delivery Stream AWS Owned\")\n        .encryption(StreamEncryption.AWS_OWNED)\n        .destinations(List.of(destination))\n        .build();\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nDeliveryStream.Builder.create(this, \"Delivery Stream Implicit Customer Managed\")\n        .encryption(StreamEncryption.CUSTOMER_MANAGED)\n        .destinations(List.of(destination))\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream Explicit Customer Managed\")\n        .encryptionKey(key)\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "declare const destination: firehose.IDestination;\n\n// SSE with an AWS-owned CMK\nnew firehose.DeliveryStream(this, 'Delivery Stream AWS Owned', {\n  encryption: firehose.StreamEncryption.AWS_OWNED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew firehose.DeliveryStream(this, 'Delivery Stream Implicit Customer Managed', {\n  encryption: firehose.StreamEncryption.CUSTOMER_MANAGED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is explicitly specified\ndeclare const key: kms.Key;\nnew firehose.DeliveryStream(this, 'Delivery Stream Explicit Customer Managed', {\n  encryptionKey: key,\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 154
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.StreamEncryption",
        "@aws-cdk/aws-kinesisfirehose.StreamEncryption#AWS_OWNED",
        "@aws-cdk/aws-kinesisfirehose.StreamEncryption#CUSTOMER_MANAGED",
        "@aws-cdk/aws-kms.IKey"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const destination: firehose.IDestination;\n// SSE with an customer-managed CMK that is explicitly specified\ndeclare const key: kms.Key;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\n\n// SSE with an AWS-owned CMK\nnew firehose.DeliveryStream(this, 'Delivery Stream AWS Owned', {\n  encryption: firehose.StreamEncryption.AWS_OWNED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew firehose.DeliveryStream(this, 'Delivery Stream Implicit Customer Managed', {\n  encryption: firehose.StreamEncryption.CUSTOMER_MANAGED,\n  destinations: [destination],\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream Explicit Customer Managed', {\n  encryptionKey: key,\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 3,
        "75": 28,
        "104": 3,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 3,
        "193": 3,
        "194": 7,
        "197": 3,
        "225": 2,
        "226": 3,
        "242": 2,
        "243": 2,
        "281": 6,
        "290": 1
      },
      "fqnsFingerprint": "da059281618503eeb4254ca396607e6fcdbfa657e966b13ec5bec220a3eead1b"
    },
    "363686fff84e9e4e330d1500a0d471caf96a6c0f76102ab34b8c70720dcff6f5": {
      "translations": {
        "python": {
          "source": "import aws_cdk.aws_logs as logs\n# bucket is of type Bucket\n\n# destination is of type IDestination\n\n\nlog_group = logs.LogGroup(self, \"Log Group\")\ndestination = destinations.S3Bucket(bucket,\n    log_group=log_group\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "using Amazon.CDK.AWS.Logs;\nBucket bucket;\n\nIDestination destination;\n\n\nLogGroup logGroup = new LogGroup(this, \"Log Group\");\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps {\n    LogGroup = logGroup\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "import software.amazon.awscdk.services.logs.*;\nBucket bucket;\n\nIDestination destination;\n\n\nLogGroup logGroup = new LogGroup(this, \"Log Group\");\nS3Bucket destination = S3Bucket.Builder.create(bucket)\n        .logGroup(logGroup)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "import * as logs from '@aws-cdk/aws-logs';\n\nconst logGroup = new logs.LogGroup(this, 'Log Group');\ndeclare const bucket: s3.Bucket;\nconst destination = new destinations.S3Bucket(bucket, {\n  logGroup: logGroup,\n});\n\ndeclare const destination: firehose.IDestination;\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 192
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-logs.ILogGroup",
        "@aws-cdk/aws-logs.LogGroup",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\nimport * as logs from '@aws-cdk/aws-logs';\ndeclare const bucket: s3.Bucket;\n\ndeclare const destination: firehose.IDestination;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\n\nconst logGroup = new logs.LogGroup(this, 'Log Group');\nconst destination = new destinations.S3Bucket(bucket, {\n  logGroup: logGroup,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 3,
        "75": 20,
        "104": 2,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 1,
        "193": 2,
        "194": 3,
        "197": 3,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "254": 1,
        "255": 1,
        "256": 1,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "0b620f547f40b8bc5bf0f2ef885ad1818de13451683a2b48730de9280539a461"
    },
    "c300ccbe48117d80cef58fe98df4aa3733c4954e044c33b64bfc524e9828b506": {
      "translations": {
        "python": {
          "source": "# bucket is of type Bucket\n\ndestination = destinations.S3Bucket(bucket,\n    logging=False\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "Bucket bucket;\n\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps {\n    Logging = false\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n\nS3Bucket destination = S3Bucket.Builder.create(bucket)\n        .logging(false)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "declare const bucket: s3.Bucket;\nconst destination = new destinations.S3Bucket(bucket, {\n  logging: false,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 209
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst destination = new destinations.S3Bucket(bucket, {\n  logging: false,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "75": 12,
        "91": 1,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 2,
        "194": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "5094b4c81d69e2e4ce145f363a0bf5fa74b5382676444857a1c487471c9a3738"
    },
    "848297b69ce6d645c767678413bbabc995be30111e01266e10bceb6fb486681b": {
      "translations": {
        "python": {
          "source": "import aws_cdk.aws_cloudwatch as cloudwatch\n# delivery_stream is of type DeliveryStream\n\n\n# Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nincoming_bytes_percent_of_limit = cloudwatch.MathExpression(\n    expression=\"incomingBytes / 300 / bytePerSecLimit\",\n    using_metrics={\n        \"incoming_bytes\": delivery_stream.metric_incoming_bytes(statistic=cloudwatch.Statistic.SUM),\n        \"byte_per_sec_limit\": delivery_stream.metric(\"BytesPerSecondLimit\")\n    }\n)\n\ncloudwatch.Alarm(self, \"Alarm\",\n    metric=incoming_bytes_percent_of_limit,\n    threshold=0.9,\n    evaluation_periods=3\n)",
          "version": "1"
        },
        "csharp": {
          "source": "using Amazon.CDK.AWS.CloudWatch;\nDeliveryStream deliveryStream;\n\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nMathExpression incomingBytesPercentOfLimit = new MathExpression(new MathExpressionProps {\n    Expression = \"incomingBytes / 300 / bytePerSecLimit\",\n    UsingMetrics = new Dictionary<string, IMetric> {\n        { \"incomingBytes\", deliveryStream.MetricIncomingBytes(new MetricOptions { Statistic = Statistic.SUM }) },\n        { \"bytePerSecLimit\", deliveryStream.Metric(\"BytesPerSecondLimit\") }\n    }\n});\n\nnew Alarm(this, \"Alarm\", new AlarmProps {\n    Metric = incomingBytesPercentOfLimit,\n    Threshold = 0.9,\n    EvaluationPeriods = 3\n});",
          "version": "1"
        },
        "java": {
          "source": "import software.amazon.awscdk.services.cloudwatch.*;\nDeliveryStream deliveryStream;\n\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nMathExpression incomingBytesPercentOfLimit = MathExpression.Builder.create()\n        .expression(\"incomingBytes / 300 / bytePerSecLimit\")\n        .usingMetrics(Map.of(\n                \"incomingBytes\", deliveryStream.metricIncomingBytes(MetricOptions.builder().statistic(Statistic.SUM).build()),\n                \"bytePerSecLimit\", deliveryStream.metric(\"BytesPerSecondLimit\")))\n        .build();\n\nAlarm.Builder.create(this, \"Alarm\")\n        .metric(incomingBytesPercentOfLimit)\n        .threshold(0.9)\n        .evaluationPeriods(3)\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "import * as cloudwatch from '@aws-cdk/aws-cloudwatch';\ndeclare const deliveryStream: firehose.DeliveryStream;\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nconst incomingBytesPercentOfLimit = new cloudwatch.MathExpression({\n  expression: 'incomingBytes / 300 / bytePerSecLimit',\n  usingMetrics: {\n    incomingBytes: deliveryStream.metricIncomingBytes({ statistic: cloudwatch.Statistic.SUM }),\n    bytePerSecLimit: deliveryStream.metric('BytesPerSecondLimit'),\n  },\n});\n\nnew cloudwatch.Alarm(this, 'Alarm', {\n  metric: incomingBytesPercentOfLimit,\n  threshold: 0.9,\n  evaluationPeriods: 3,\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 239
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-cloudwatch.Alarm",
        "@aws-cdk/aws-cloudwatch.AlarmProps",
        "@aws-cdk/aws-cloudwatch.IMetric",
        "@aws-cdk/aws-cloudwatch.MathExpression",
        "@aws-cdk/aws-cloudwatch.MathExpressionProps",
        "@aws-cdk/aws-cloudwatch.MetricOptions",
        "@aws-cdk/aws-cloudwatch.Statistic",
        "@aws-cdk/aws-cloudwatch.Statistic#SUM"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\nimport * as cloudwatch from '@aws-cdk/aws-cloudwatch';\ndeclare const deliveryStream: firehose.DeliveryStream;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nconst incomingBytesPercentOfLimit = new cloudwatch.MathExpression({\n  expression: 'incomingBytes / 300 / bytePerSecLimit',\n  usingMetrics: {\n    incomingBytes: deliveryStream.metricIncomingBytes({ statistic: cloudwatch.Statistic.SUM }),\n    bytePerSecLimit: deliveryStream.metric('BytesPerSecondLimit'),\n  },\n});\n\nnew cloudwatch.Alarm(this, 'Alarm', {\n  metric: incomingBytesPercentOfLimit,\n  threshold: 0.9,\n  evaluationPeriods: 3,\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 2,
        "10": 4,
        "75": 25,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "193": 4,
        "194": 6,
        "196": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "254": 1,
        "255": 1,
        "256": 1,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "60ed3ac3ec0fb8c47dfcfb9a9415a0430321859cfe1fe4d0c5b63020d4b3a06a"
    },
    "1d0b5ee3e0c2146e01786b63893f1bb64375051e8f12fa7b70b2fb23813fc4b3": {
      "translations": {
        "python": {
          "source": "# Compress data delivered to S3 using Snappy\n# bucket is of type Bucket\n\ns3_destination = destinations.S3Bucket(bucket,\n    compression=destinations.Compression.SNAPPY\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "// Compress data delivered to S3 using Snappy\nBucket bucket;\n\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Compression = Compression.SNAPPY\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "// Compress data delivered to S3 using Snappy\nBucket bucket;\n\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .compression(Compression.SNAPPY)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "// Compress data delivered to S3 using Snappy\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  compression: destinations.Compression.SNAPPY,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 270
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#SNAPPY",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// Compress data delivered to S3 using Snappy\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  compression: destinations.Compression.SNAPPY,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "75": 15,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 2,
        "194": 4,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "f049ce7eb42c636b771e2a676b0d4edc8359420e0914fecb5fe12946cd608845"
    },
    "bfb124fbb64475d96fa43b5e7953a2cb99dc3413972bfa69ca72c3adb1602aeb": {
      "translations": {
        "python": {
          "source": "# Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\n# bucket is of type Bucket\n\ndestination = destinations.S3Bucket(bucket,\n    buffering_interval=Duration.minutes(10),\n    buffering_size=Size.mebibytes(8)\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\nBucket bucket;\n\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps {\n    BufferingInterval = Duration.Minutes(10),\n    BufferingSize = Size.Mebibytes(8)\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\nBucket bucket;\n\nS3Bucket destination = S3Bucket.Builder.create(bucket)\n        .bufferingInterval(Duration.minutes(10))\n        .bufferingSize(Size.mebibytes(8))\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\ndeclare const bucket: s3.Bucket;\nconst destination = new destinations.S3Bucket(bucket, {\n  bufferingInterval: Duration.minutes(10),\n  bufferingSize: Size.mebibytes(8),\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 290
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-s3.IBucket",
        "@aws-cdk/core.Duration",
        "@aws-cdk/core.Duration#minutes",
        "@aws-cdk/core.Size",
        "@aws-cdk/core.Size#mebibytes"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst destination = new destinations.S3Bucket(bucket, {\n  bufferingInterval: Duration.minutes(10),\n  bufferingSize: Size.mebibytes(8),\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 2,
        "10": 1,
        "75": 17,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 2,
        "194": 4,
        "196": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 3,
        "290": 1
      },
      "fqnsFingerprint": "e57c2c661689b3bba252d94db27c759aa14f98e04f41aae268e0aaa5b0bfc83c"
    },
    "80c9d073e102778895dfbe511d7dbfd66709ce9c3310db200d75f8e6fe9fc7ee": {
      "translations": {
        "python": {
          "source": "# bucket is of type Bucket\n# key is of type Key\n\ndestination = destinations.S3Bucket(bucket,\n    encryption_key=key\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "Bucket bucket;\nKey key;\n\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps {\n    EncryptionKey = key\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\nKey key;\n\nS3Bucket destination = S3Bucket.Builder.create(bucket)\n        .encryptionKey(key)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "declare const bucket: s3.Bucket;\ndeclare const key: kms.Key;\nconst destination = new destinations.S3Bucket(bucket, {\n  encryptionKey: key,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 314
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kms.IKey",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const bucket: s3.Bucket;\ndeclare const key: kms.Key;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst destination = new destinations.S3Bucket(bucket, {\n  encryptionKey: key,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "75": 16,
        "104": 1,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 1,
        "193": 2,
        "194": 2,
        "197": 2,
        "225": 3,
        "226": 1,
        "242": 3,
        "243": 3,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "30380291248ed9964f5071b249ccb50801cb2c2733c405d96cfb7116447f88df"
    },
    "53b8c7107c307b7364ee23b694304774dacab6471db87b10d9142934c912ea50": {
      "translations": {
        "python": {
          "source": "# Enable backup of all source records (to an S3 bucket created by CDK).\n# bucket is of type Bucket\n# Explicitly provide an S3 bucket to which all source records will be backed up.\n# backup_bucket is of type Bucket\n\nfirehose.DeliveryStream(self, \"Delivery Stream Backup All\",\n    destinations=[\n        destinations.S3Bucket(bucket,\n            s3_backup=destinations.DestinationS3BackupProps(\n                mode=destinations.BackupMode.ALL\n            )\n        )\n    ]\n)\nfirehose.DeliveryStream(self, \"Delivery Stream Backup All Explicit Bucket\",\n    destinations=[\n        destinations.S3Bucket(bucket,\n            s3_backup=destinations.DestinationS3BackupProps(\n                bucket=backup_bucket\n            )\n        )\n    ]\n)\n# Explicitly provide an S3 prefix under which all source records will be backed up.\nfirehose.DeliveryStream(self, \"Delivery Stream Backup All Explicit Prefix\",\n    destinations=[\n        destinations.S3Bucket(bucket,\n            s3_backup=destinations.DestinationS3BackupProps(\n                mode=destinations.BackupMode.ALL,\n                data_output_prefix=\"mybackup\"\n            )\n        )\n    ]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "// Enable backup of all source records (to an S3 bucket created by CDK).\nBucket bucket;\n// Explicitly provide an S3 bucket to which all source records will be backed up.\nBucket backupBucket;\n\nnew DeliveryStream(this, \"Delivery Stream Backup All\", new DeliveryStreamProps {\n    Destinations = new [] {\n        new S3Bucket(bucket, new S3BucketProps {\n            S3Backup = new DestinationS3BackupProps {\n                Mode = BackupMode.ALL\n            }\n        }) }\n});\nnew DeliveryStream(this, \"Delivery Stream Backup All Explicit Bucket\", new DeliveryStreamProps {\n    Destinations = new [] {\n        new S3Bucket(bucket, new S3BucketProps {\n            S3Backup = new DestinationS3BackupProps {\n                Bucket = backupBucket\n            }\n        }) }\n});\n// Explicitly provide an S3 prefix under which all source records will be backed up.\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nnew DeliveryStream(this, \"Delivery Stream Backup All Explicit Prefix\", new DeliveryStreamProps {\n    Destinations = new [] {\n        new S3Bucket(bucket, new S3BucketProps {\n            S3Backup = new DestinationS3BackupProps {\n                Mode = BackupMode.ALL,\n                DataOutputPrefix = \"mybackup\"\n            }\n        }) }\n});",
          "version": "1"
        },
        "java": {
          "source": "// Enable backup of all source records (to an S3 bucket created by CDK).\nBucket bucket;\n// Explicitly provide an S3 bucket to which all source records will be backed up.\nBucket backupBucket;\n\nDeliveryStream.Builder.create(this, \"Delivery Stream Backup All\")\n        .destinations(List.of(\n            S3Bucket.Builder.create(bucket)\n                    .s3Backup(DestinationS3BackupProps.builder()\n                            .mode(BackupMode.ALL)\n                            .build())\n                    .build()))\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream Backup All Explicit Bucket\")\n        .destinations(List.of(\n            S3Bucket.Builder.create(bucket)\n                    .s3Backup(DestinationS3BackupProps.builder()\n                            .bucket(backupBucket)\n                            .build())\n                    .build()))\n        .build();\n// Explicitly provide an S3 prefix under which all source records will be backed up.\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nDeliveryStream.Builder.create(this, \"Delivery Stream Backup All Explicit Prefix\")\n        .destinations(List.of(\n            S3Bucket.Builder.create(bucket)\n                    .s3Backup(DestinationS3BackupProps.builder()\n                            .mode(BackupMode.ALL)\n                            .dataOutputPrefix(\"mybackup\")\n                            .build())\n                    .build()))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "// Enable backup of all source records (to an S3 bucket created by CDK).\ndeclare const bucket: s3.Bucket;\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        mode: destinations.BackupMode.ALL,\n      },\n    }),\n  ],\n});\n// Explicitly provide an S3 bucket to which all source records will be backed up.\ndeclare const backupBucket: s3.Bucket;\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All Explicit Bucket', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        bucket: backupBucket,\n      },\n    }),\n  ],\n});\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All Explicit Prefix', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        mode: destinations.BackupMode.ALL,\n        dataOutputPrefix: 'mybackup',\n      },\n    }),\n  ],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 335
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// Enable backup of all source records (to an S3 bucket created by CDK).\ndeclare const bucket: s3.Bucket;\n// Explicitly provide an S3 bucket to which all source records will be backed up.\ndeclare const backupBucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        mode: destinations.BackupMode.ALL,\n      },\n    }),\n  ],\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All Explicit Bucket', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        bucket: backupBucket,\n      },\n    }),\n  ],\n});\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All Explicit Prefix', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        mode: destinations.BackupMode.ALL,\n        dataOutputPrefix: 'mybackup',\n      },\n    }),\n  ],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 4,
        "75": 38,
        "104": 3,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 3,
        "193": 9,
        "194": 10,
        "197": 6,
        "225": 2,
        "226": 3,
        "242": 2,
        "243": 2,
        "281": 10,
        "290": 1
      },
      "fqnsFingerprint": "79f514f3b64974e6c225726c91b09d68608cfbba97ee44d89a49dda91aac81d6"
    },
    "d8c05e8556031e5b0bb2c02fea58d3bbeefd893db21c66542be79b23eae39178": {
      "translations": {
        "python": {
          "source": "# bucket is of type Bucket\n# Provide a Lambda function that will transform records before delivery, with custom\n# buffering and retry configuration\nlambda_function = lambda_.Function(self, \"Processor\",\n    runtime=lambda_.Runtime.NODEJS_12_X,\n    handler=\"index.handler\",\n    code=lambda_.Code.from_asset(path.join(__dirname, \"process-records\"))\n)\nlambda_processor = firehose.LambdaFunctionProcessor(lambda_function,\n    buffer_interval=Duration.minutes(5),\n    buffer_size=Size.mebibytes(5),\n    retries=5\n)\ns3_destination = destinations.S3Bucket(bucket,\n    processor=lambda_processor\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = new Function(this, \"Processor\", new FunctionProps {\n    Runtime = Runtime.NODEJS_12_X,\n    Handler = \"index.handler\",\n    Code = Code.FromAsset(Join(__dirname, \"process-records\"))\n});\nLambdaFunctionProcessor lambdaProcessor = new LambdaFunctionProcessor(lambdaFunction, new DataProcessorProps {\n    BufferInterval = Duration.Minutes(5),\n    BufferSize = Size.Mebibytes(5),\n    Retries = 5\n});\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Processor = lambdaProcessor\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = Function.Builder.create(this, \"Processor\")\n        .runtime(Runtime.NODEJS_12_X)\n        .handler(\"index.handler\")\n        .code(Code.fromAsset(join(__dirname, \"process-records\")))\n        .build();\nLambdaFunctionProcessor lambdaProcessor = LambdaFunctionProcessor.Builder.create(lambdaFunction)\n        .bufferInterval(Duration.minutes(5))\n        .bufferSize(Size.mebibytes(5))\n        .retries(5)\n        .build();\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .processor(lambdaProcessor)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 401
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose.LambdaFunctionProcessor",
        "@aws-cdk/aws-lambda.Code",
        "@aws-cdk/aws-lambda.Code#fromAsset",
        "@aws-cdk/aws-lambda.Function",
        "@aws-cdk/aws-lambda.FunctionProps",
        "@aws-cdk/aws-lambda.IFunction",
        "@aws-cdk/aws-lambda.Runtime",
        "@aws-cdk/aws-lambda.Runtime#NODEJS_12_X",
        "@aws-cdk/aws-s3.IBucket",
        "@aws-cdk/core.Duration",
        "@aws-cdk/core.Duration#minutes",
        "@aws-cdk/core.Size",
        "@aws-cdk/core.Size#mebibytes"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 3,
        "10": 4,
        "75": 39,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 11,
        "196": 4,
        "197": 4,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "8646855cfd66cb6361ad5fd3e2ce05c3809ddb9dd91bebe07226bdec1ea829cf"
    },
    "a35e53264628a3e00bf555fd3cb17854d35eea0ab95af94e20d0c9994499c5a5": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk.core as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "1"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.core.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 423
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose.LambdaFunctionProcessor",
        "@aws-cdk/aws-kms.IKey",
        "@aws-cdk/aws-kms.Key",
        "@aws-cdk/aws-kms.KeyProps",
        "@aws-cdk/aws-lambda-nodejs.NodejsFunction",
        "@aws-cdk/aws-lambda-nodejs.NodejsFunctionProps",
        "@aws-cdk/aws-lambda.IFunction",
        "@aws-cdk/aws-logs.ILogGroup",
        "@aws-cdk/aws-logs.LogGroup",
        "@aws-cdk/aws-logs.LogGroupProps",
        "@aws-cdk/aws-s3.Bucket",
        "@aws-cdk/aws-s3.BucketProps",
        "@aws-cdk/aws-s3.IBucket",
        "@aws-cdk/core.App",
        "@aws-cdk/core.Construct",
        "@aws-cdk/core.Duration",
        "@aws-cdk/core.Duration#minutes",
        "@aws-cdk/core.Duration#seconds",
        "@aws-cdk/core.RemovalPolicy",
        "@aws-cdk/core.RemovalPolicy#DESTROY",
        "@aws-cdk/core.Size",
        "@aws-cdk/core.Size#mebibytes",
        "@aws-cdk/core.Stack",
        "@aws-cdk/core.Stage#synth"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as lambdanodejs from '@aws-cdk/aws-lambda-nodejs';\nimport * as logs from '@aws-cdk/aws-logs';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as cdk from '@aws-cdk/core';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "6b2167a475fe5ff423f6b911a6df58510bdbac5e8afe5210434108d135a86124"
    },
    "2aba0fb1ea9e2556cc7caab73fce5d9f71a999c35c4d1df019cf4d5ecb8639ed": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk.core as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "1"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.core.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "$": {
          "source": "import * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as lambdanodejs from '@aws-cdk/aws-lambda-nodejs';\nimport * as logs from '@aws-cdk/aws-logs';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as cdk from '@aws-cdk/core';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 427
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose.LambdaFunctionProcessor",
        "@aws-cdk/aws-kms.IKey",
        "@aws-cdk/aws-kms.Key",
        "@aws-cdk/aws-kms.KeyProps",
        "@aws-cdk/aws-lambda-nodejs.NodejsFunction",
        "@aws-cdk/aws-lambda-nodejs.NodejsFunctionProps",
        "@aws-cdk/aws-lambda.IFunction",
        "@aws-cdk/aws-logs.ILogGroup",
        "@aws-cdk/aws-logs.LogGroup",
        "@aws-cdk/aws-logs.LogGroupProps",
        "@aws-cdk/aws-s3.Bucket",
        "@aws-cdk/aws-s3.BucketProps",
        "@aws-cdk/aws-s3.IBucket",
        "@aws-cdk/core.App",
        "@aws-cdk/core.Construct",
        "@aws-cdk/core.Duration",
        "@aws-cdk/core.Duration#minutes",
        "@aws-cdk/core.Duration#seconds",
        "@aws-cdk/core.RemovalPolicy",
        "@aws-cdk/core.RemovalPolicy#DESTROY",
        "@aws-cdk/core.Size",
        "@aws-cdk/core.Size#mebibytes",
        "@aws-cdk/core.Stack",
        "@aws-cdk/core.Stage#synth"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as lambdanodejs from '@aws-cdk/aws-lambda-nodejs';\nimport * as logs from '@aws-cdk/aws-logs';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as cdk from '@aws-cdk/core';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "6b2167a475fe5ff423f6b911a6df58510bdbac5e8afe5210434108d135a86124"
    },
    "687db5597d09307051aae3938afd4be3dba3012bfb83444874255d4b52334e2a": {
      "translations": {
        "python": {
          "source": "# Specify the roles created above when defining the destination and delivery stream.\n# bucket is of type Bucket\n# Create service roles for the delivery stream and destination.\n# These can be used for other purposes and granted access to different resources.\n# They must include the Kinesis Data Firehose service principal in their trust policies.\n# Two separate roles are shown below, but the same role can be used for both purposes.\ndelivery_stream_role = iam.Role(self, \"Delivery Stream Role\",\n    assumed_by=iam.ServicePrincipal(\"firehose.amazonaws.com\")\n)\ndestination_role = iam.Role(self, \"Destination Role\",\n    assumed_by=iam.ServicePrincipal(\"firehose.amazonaws.com\")\n)\ndestination = destinations.S3Bucket(bucket, role=destination_role)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination],\n    role=delivery_stream_role\n)",
          "version": "1"
        },
        "csharp": {
          "source": "// Specify the roles created above when defining the destination and delivery stream.\nBucket bucket;\n// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\nRole deliveryStreamRole = new Role(this, \"Delivery Stream Role\", new RoleProps {\n    AssumedBy = new ServicePrincipal(\"firehose.amazonaws.com\")\n});\nRole destinationRole = new Role(this, \"Destination Role\", new RoleProps {\n    AssumedBy = new ServicePrincipal(\"firehose.amazonaws.com\")\n});\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps { Role = destinationRole });\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination },\n    Role = deliveryStreamRole\n});",
          "version": "1"
        },
        "java": {
          "source": "// Specify the roles created above when defining the destination and delivery stream.\nBucket bucket;\n// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\nRole deliveryStreamRole = Role.Builder.create(this, \"Delivery Stream Role\")\n        .assumedBy(new ServicePrincipal(\"firehose.amazonaws.com\"))\n        .build();\nRole destinationRole = Role.Builder.create(this, \"Destination Role\")\n        .assumedBy(new ServicePrincipal(\"firehose.amazonaws.com\"))\n        .build();\nS3Bucket destination = S3Bucket.Builder.create(bucket).role(destinationRole).build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .role(deliveryStreamRole)\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\nconst deliveryStreamRole = new iam.Role(this, 'Delivery Stream Role', {\n  assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n});\nconst destinationRole = new iam.Role(this, 'Destination Role', {\n  assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n});\n\n// Specify the roles created above when defining the destination and delivery stream.\ndeclare const bucket: s3.Bucket;\nconst destination = new destinations.S3Bucket(bucket, { role: destinationRole });\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n  role: deliveryStreamRole,\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 519
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-iam.IPrincipal",
        "@aws-cdk/aws-iam.IRole",
        "@aws-cdk/aws-iam.Role",
        "@aws-cdk/aws-iam.RoleProps",
        "@aws-cdk/aws-iam.ServicePrincipal",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\n\n// Specify the roles created above when defining the destination and delivery stream.\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\nconst deliveryStreamRole = new iam.Role(this, 'Delivery Stream Role', {\n  assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n});\nconst destinationRole = new iam.Role(this, 'Destination Role', {\n  assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n});\nconst destination = new destinations.S3Bucket(bucket, { role: destinationRole });\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n  role: deliveryStreamRole,\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 5,
        "75": 27,
        "104": 3,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 6,
        "197": 6,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 5,
        "290": 1
      },
      "fqnsFingerprint": "c9994128c1fe5c32f06401b05b1eb7716176baedf3a821e45a6cf4ca6532275f"
    },
    "3ddb74265eb034508b99b8eaa16ee16591675b3b828d6579bdec85e4f5611b3e": {
      "translations": {
        "python": {
          "source": "# Give the role permissions to write data to the delivery stream\n# delivery_stream is of type DeliveryStream\nlambda_role = iam.Role(self, \"Role\",\n    assumed_by=iam.ServicePrincipal(\"lambda.amazonaws.com\")\n)\ndelivery_stream.grant_put_records(lambda_role)",
          "version": "1"
        },
        "csharp": {
          "source": "// Give the role permissions to write data to the delivery stream\nDeliveryStream deliveryStream;\nRole lambdaRole = new Role(this, \"Role\", new RoleProps {\n    AssumedBy = new ServicePrincipal(\"lambda.amazonaws.com\")\n});\ndeliveryStream.GrantPutRecords(lambdaRole);",
          "version": "1"
        },
        "java": {
          "source": "// Give the role permissions to write data to the delivery stream\nDeliveryStream deliveryStream;\nRole lambdaRole = Role.Builder.create(this, \"Role\")\n        .assumedBy(new ServicePrincipal(\"lambda.amazonaws.com\"))\n        .build();\ndeliveryStream.grantPutRecords(lambdaRole);",
          "version": "1"
        },
        "$": {
          "source": "const lambdaRole = new iam.Role(this, 'Role', {\n  assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n});\n\n// Give the role permissions to write data to the delivery stream\ndeclare const deliveryStream: firehose.DeliveryStream;\ndeliveryStream.grantPutRecords(lambdaRole);",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 556
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-iam.IGrantable",
        "@aws-cdk/aws-iam.IPrincipal",
        "@aws-cdk/aws-iam.Role",
        "@aws-cdk/aws-iam.RoleProps",
        "@aws-cdk/aws-iam.ServicePrincipal"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\n\n// Give the role permissions to write data to the delivery stream\ndeclare const deliveryStream: firehose.DeliveryStream;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\nconst lambdaRole = new iam.Role(this, 'Role', {\n  assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n});\ndeliveryStream.grantPutRecords(lambdaRole);\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 2,
        "75": 12,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "193": 1,
        "194": 3,
        "196": 1,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 1,
        "290": 1
      },
      "fqnsFingerprint": "330b2348373d8a75b2e4c4822b01b22f0aaa8d67ded66e0a5b478abdb1e069d1"
    },
    "a4f493588831b954ab9a8f77262ffc89e86afdb34dbecb78ef4c364a4c7c86a0": {
      "translations": {
        "python": {
          "source": "# delivery_stream is of type DeliveryStream\nfn = lambda_.Function(self, \"Function\",\n    code=lambda_.Code.from_inline(\"exports.handler = (event) => {}\"),\n    runtime=lambda_.Runtime.NODEJS_14_X,\n    handler=\"index.handler\"\n)\nfn.grant_invoke(delivery_stream)",
          "version": "1"
        },
        "csharp": {
          "source": "DeliveryStream deliveryStream;\nFunction fn = new Function(this, \"Function\", new FunctionProps {\n    Code = Code.FromInline(\"exports.handler = (event) => {}\"),\n    Runtime = Runtime.NODEJS_14_X,\n    Handler = \"index.handler\"\n});\nfn.GrantInvoke(deliveryStream);",
          "version": "1"
        },
        "java": {
          "source": "DeliveryStream deliveryStream;\nFunction fn = Function.Builder.create(this, \"Function\")\n        .code(Code.fromInline(\"exports.handler = (event) => {}\"))\n        .runtime(Runtime.NODEJS_14_X)\n        .handler(\"index.handler\")\n        .build();\nfn.grantInvoke(deliveryStream);",
          "version": "1"
        },
        "$": {
          "source": "const fn = new lambda.Function(this, 'Function', {\n  code: lambda.Code.fromInline('exports.handler = (event) => {}'),\n  runtime: lambda.Runtime.NODEJS_14_X,\n  handler: 'index.handler',\n});\n\ndeclare const deliveryStream: firehose.DeliveryStream;\nfn.grantInvoke(deliveryStream);",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose"
        },
        "field": {
          "field": "markdown",
          "line": 581
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-iam.IGrantable",
        "@aws-cdk/aws-lambda.Code",
        "@aws-cdk/aws-lambda.Code#fromInline",
        "@aws-cdk/aws-lambda.Function",
        "@aws-cdk/aws-lambda.FunctionBase#grantInvoke",
        "@aws-cdk/aws-lambda.FunctionProps",
        "@aws-cdk/aws-lambda.Runtime",
        "@aws-cdk/aws-lambda.Runtime#NODEJS_14_X"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\n\ndeclare const deliveryStream: firehose.DeliveryStream;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\nconst fn = new lambda.Function(this, 'Function', {\n  code: lambda.Code.fromInline('exports.handler = (event) => {}'),\n  runtime: lambda.Runtime.NODEJS_14_X,\n  handler: 'index.handler',\n});\nfn.grantInvoke(deliveryStream);\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 3,
        "75": 18,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "193": 1,
        "194": 6,
        "196": 2,
        "197": 1,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 3,
        "290": 1
      },
      "fqnsFingerprint": "629ddc9eb027bd5eab2f4c1cc43381e762a61da03d0314c3c066d4b9e4442478"
    },
    "3258b5e136093f1dfeab533a2ad89d72ec6851b54cd7a2a9c889fb5e07169a70": {
      "translations": {
        "python": {
          "source": "\"Lambda\"",
          "version": "1"
        },
        "csharp": {
          "source": "\"Lambda\";",
          "version": "1"
        },
        "java": {
          "source": "\"Lambda\";",
          "version": "1"
        },
        "$": {
          "source": "'Lambda'",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "member",
          "fqn": "@aws-cdk/aws-kinesisfirehose.DataProcessorConfig",
          "memberName": "processorType"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [],
      "fullSource": "// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n'Lambda'\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "226": 1
      },
      "fqnsFingerprint": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
    },
    "728e4898acc9395db16bd1f6918b9c1387557c9e2fc7b878a8761624c967b475": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk.core as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "1"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.core.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose.DataProcessorProps"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose.LambdaFunctionProcessor",
        "@aws-cdk/aws-kms.IKey",
        "@aws-cdk/aws-kms.Key",
        "@aws-cdk/aws-kms.KeyProps",
        "@aws-cdk/aws-lambda-nodejs.NodejsFunction",
        "@aws-cdk/aws-lambda-nodejs.NodejsFunctionProps",
        "@aws-cdk/aws-lambda.IFunction",
        "@aws-cdk/aws-logs.ILogGroup",
        "@aws-cdk/aws-logs.LogGroup",
        "@aws-cdk/aws-logs.LogGroupProps",
        "@aws-cdk/aws-s3.Bucket",
        "@aws-cdk/aws-s3.BucketProps",
        "@aws-cdk/aws-s3.IBucket",
        "@aws-cdk/core.App",
        "@aws-cdk/core.Construct",
        "@aws-cdk/core.Duration",
        "@aws-cdk/core.Duration#minutes",
        "@aws-cdk/core.Duration#seconds",
        "@aws-cdk/core.RemovalPolicy",
        "@aws-cdk/core.RemovalPolicy#DESTROY",
        "@aws-cdk/core.Size",
        "@aws-cdk/core.Size#mebibytes",
        "@aws-cdk/core.Stack",
        "@aws-cdk/core.Stage#synth"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as lambdanodejs from '@aws-cdk/aws-lambda-nodejs';\nimport * as logs from '@aws-cdk/aws-logs';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as cdk from '@aws-cdk/core';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "6b2167a475fe5ff423f6b911a6df58510bdbac5e8afe5210434108d135a86124"
    },
    "f6e411edcf9706762f4304192d14a29318969be1f85c08dddd7af3a7e7e6fd74": {
      "translations": {
        "python": {
          "source": "# bucket is of type Bucket\n# Provide a Lambda function that will transform records before delivery, with custom\n# buffering and retry configuration\nlambda_function = lambda_.Function(self, \"Processor\",\n    runtime=lambda_.Runtime.NODEJS_12_X,\n    handler=\"index.handler\",\n    code=lambda_.Code.from_asset(path.join(__dirname, \"process-records\"))\n)\nlambda_processor = firehose.LambdaFunctionProcessor(lambda_function,\n    buffer_interval=Duration.minutes(5),\n    buffer_size=Size.mebibytes(5),\n    retries=5\n)\ns3_destination = destinations.S3Bucket(bucket,\n    processor=lambda_processor\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = new Function(this, \"Processor\", new FunctionProps {\n    Runtime = Runtime.NODEJS_12_X,\n    Handler = \"index.handler\",\n    Code = Code.FromAsset(Join(__dirname, \"process-records\"))\n});\nLambdaFunctionProcessor lambdaProcessor = new LambdaFunctionProcessor(lambdaFunction, new DataProcessorProps {\n    BufferInterval = Duration.Minutes(5),\n    BufferSize = Size.Mebibytes(5),\n    Retries = 5\n});\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Processor = lambdaProcessor\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = Function.Builder.create(this, \"Processor\")\n        .runtime(Runtime.NODEJS_12_X)\n        .handler(\"index.handler\")\n        .code(Code.fromAsset(join(__dirname, \"process-records\")))\n        .build();\nLambdaFunctionProcessor lambdaProcessor = LambdaFunctionProcessor.Builder.create(lambdaFunction)\n        .bufferInterval(Duration.minutes(5))\n        .bufferSize(Size.mebibytes(5))\n        .retries(5)\n        .build();\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .processor(lambdaProcessor)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose.DeliveryStream"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose.LambdaFunctionProcessor",
        "@aws-cdk/aws-lambda.Code",
        "@aws-cdk/aws-lambda.Code#fromAsset",
        "@aws-cdk/aws-lambda.Function",
        "@aws-cdk/aws-lambda.FunctionProps",
        "@aws-cdk/aws-lambda.IFunction",
        "@aws-cdk/aws-lambda.Runtime",
        "@aws-cdk/aws-lambda.Runtime#NODEJS_12_X",
        "@aws-cdk/aws-s3.IBucket",
        "@aws-cdk/core.Duration",
        "@aws-cdk/core.Duration#minutes",
        "@aws-cdk/core.Size",
        "@aws-cdk/core.Size#mebibytes"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 3,
        "10": 4,
        "75": 39,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 11,
        "196": 4,
        "197": 4,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "8646855cfd66cb6361ad5fd3e2ce05c3809ddb9dd91bebe07226bdec1ea829cf"
    },
    "c28465ba794cb62db31aa7d5c1219d0522ab77ff591c58dca17cc6791f4fcc8a": {
      "translations": {
        "python": {
          "source": "# bucket is of type Bucket\n# Provide a Lambda function that will transform records before delivery, with custom\n# buffering and retry configuration\nlambda_function = lambda_.Function(self, \"Processor\",\n    runtime=lambda_.Runtime.NODEJS_12_X,\n    handler=\"index.handler\",\n    code=lambda_.Code.from_asset(path.join(__dirname, \"process-records\"))\n)\nlambda_processor = firehose.LambdaFunctionProcessor(lambda_function,\n    buffer_interval=Duration.minutes(5),\n    buffer_size=Size.mebibytes(5),\n    retries=5\n)\ns3_destination = destinations.S3Bucket(bucket,\n    processor=lambda_processor\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = new Function(this, \"Processor\", new FunctionProps {\n    Runtime = Runtime.NODEJS_12_X,\n    Handler = \"index.handler\",\n    Code = Code.FromAsset(Join(__dirname, \"process-records\"))\n});\nLambdaFunctionProcessor lambdaProcessor = new LambdaFunctionProcessor(lambdaFunction, new DataProcessorProps {\n    BufferInterval = Duration.Minutes(5),\n    BufferSize = Size.Mebibytes(5),\n    Retries = 5\n});\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Processor = lambdaProcessor\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = Function.Builder.create(this, \"Processor\")\n        .runtime(Runtime.NODEJS_12_X)\n        .handler(\"index.handler\")\n        .code(Code.fromAsset(join(__dirname, \"process-records\")))\n        .build();\nLambdaFunctionProcessor lambdaProcessor = LambdaFunctionProcessor.Builder.create(lambdaFunction)\n        .bufferInterval(Duration.minutes(5))\n        .bufferSize(Size.mebibytes(5))\n        .retries(5)\n        .build();\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .processor(lambdaProcessor)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose.LambdaFunctionProcessor",
        "@aws-cdk/aws-lambda.Code",
        "@aws-cdk/aws-lambda.Code#fromAsset",
        "@aws-cdk/aws-lambda.Function",
        "@aws-cdk/aws-lambda.FunctionProps",
        "@aws-cdk/aws-lambda.IFunction",
        "@aws-cdk/aws-lambda.Runtime",
        "@aws-cdk/aws-lambda.Runtime#NODEJS_12_X",
        "@aws-cdk/aws-s3.IBucket",
        "@aws-cdk/core.Duration",
        "@aws-cdk/core.Duration#minutes",
        "@aws-cdk/core.Size",
        "@aws-cdk/core.Size#mebibytes"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 3,
        "10": 4,
        "75": 39,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 11,
        "196": 4,
        "197": 4,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "8646855cfd66cb6361ad5fd3e2ce05c3809ddb9dd91bebe07226bdec1ea829cf"
    },
    "605a9ab5c38071c62b61107b3514f855d3532283826b38f7848f10b233349967": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk.core as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "1"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.core.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose.LambdaFunctionProcessor"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations.S3BucketProps",
        "@aws-cdk/aws-kinesisfirehose.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose.LambdaFunctionProcessor",
        "@aws-cdk/aws-kms.IKey",
        "@aws-cdk/aws-kms.Key",
        "@aws-cdk/aws-kms.KeyProps",
        "@aws-cdk/aws-lambda-nodejs.NodejsFunction",
        "@aws-cdk/aws-lambda-nodejs.NodejsFunctionProps",
        "@aws-cdk/aws-lambda.IFunction",
        "@aws-cdk/aws-logs.ILogGroup",
        "@aws-cdk/aws-logs.LogGroup",
        "@aws-cdk/aws-logs.LogGroupProps",
        "@aws-cdk/aws-s3.Bucket",
        "@aws-cdk/aws-s3.BucketProps",
        "@aws-cdk/aws-s3.IBucket",
        "@aws-cdk/core.App",
        "@aws-cdk/core.Construct",
        "@aws-cdk/core.Duration",
        "@aws-cdk/core.Duration#minutes",
        "@aws-cdk/core.Duration#seconds",
        "@aws-cdk/core.RemovalPolicy",
        "@aws-cdk/core.RemovalPolicy#DESTROY",
        "@aws-cdk/core.Size",
        "@aws-cdk/core.Size#mebibytes",
        "@aws-cdk/core.Stack",
        "@aws-cdk/core.Stage#synth"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as lambdanodejs from '@aws-cdk/aws-lambda-nodejs';\nimport * as logs from '@aws-cdk/aws-logs';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as cdk from '@aws-cdk/core';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "6b2167a475fe5ff423f6b911a6df58510bdbac5e8afe5210434108d135a86124"
    },
    "d4e7efa2286d6c274052f861788d186b6c0249db4d9be4aa93f190a4c82fd985": {
      "translations": {
        "python": {
          "source": "# destination is of type IDestination\n# SSE with an customer-managed CMK that is explicitly specified\n# key is of type Key\n\n\n# SSE with an AWS-owned CMK\nfirehose.DeliveryStream(self, \"Delivery Stream AWS Owned\",\n    encryption=firehose.StreamEncryption.AWS_OWNED,\n    destinations=[destination]\n)\n# SSE with an customer-managed CMK that is created automatically by the CDK\nfirehose.DeliveryStream(self, \"Delivery Stream Implicit Customer Managed\",\n    encryption=firehose.StreamEncryption.CUSTOMER_MANAGED,\n    destinations=[destination]\n)\nfirehose.DeliveryStream(self, \"Delivery Stream Explicit Customer Managed\",\n    encryption_key=key,\n    destinations=[destination]\n)",
          "version": "1"
        },
        "csharp": {
          "source": "IDestination destination;\n// SSE with an customer-managed CMK that is explicitly specified\nKey key;\n\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nnew DeliveryStream(this, \"Delivery Stream AWS Owned\", new DeliveryStreamProps {\n    Encryption = StreamEncryption.AWS_OWNED,\n    Destinations = new [] { destination }\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew DeliveryStream(this, \"Delivery Stream Implicit Customer Managed\", new DeliveryStreamProps {\n    Encryption = StreamEncryption.CUSTOMER_MANAGED,\n    Destinations = new [] { destination }\n});\nnew DeliveryStream(this, \"Delivery Stream Explicit Customer Managed\", new DeliveryStreamProps {\n    EncryptionKey = key,\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "IDestination destination;\n// SSE with an customer-managed CMK that is explicitly specified\nKey key;\n\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nDeliveryStream.Builder.create(this, \"Delivery Stream AWS Owned\")\n        .encryption(StreamEncryption.AWS_OWNED)\n        .destinations(List.of(destination))\n        .build();\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nDeliveryStream.Builder.create(this, \"Delivery Stream Implicit Customer Managed\")\n        .encryption(StreamEncryption.CUSTOMER_MANAGED)\n        .destinations(List.of(destination))\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream Explicit Customer Managed\")\n        .encryptionKey(key)\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "$": {
          "source": "declare const destination: firehose.IDestination;\n\n// SSE with an AWS-owned CMK\nnew firehose.DeliveryStream(this, 'Delivery Stream AWS Owned', {\n  encryption: firehose.StreamEncryption.AWS_OWNED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew firehose.DeliveryStream(this, 'Delivery Stream Implicit Customer Managed', {\n  encryption: firehose.StreamEncryption.CUSTOMER_MANAGED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is explicitly specified\ndeclare const key: kms.Key;\nnew firehose.DeliveryStream(this, 'Delivery Stream Explicit Customer Managed', {\n  encryptionKey: key,\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose.StreamEncryption"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose.StreamEncryption",
        "@aws-cdk/aws-kinesisfirehose.StreamEncryption#AWS_OWNED",
        "@aws-cdk/aws-kinesisfirehose.StreamEncryption#CUSTOMER_MANAGED",
        "@aws-cdk/aws-kms.IKey"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const destination: firehose.IDestination;\n// SSE with an customer-managed CMK that is explicitly specified\ndeclare const key: kms.Key;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from '@aws-cdk/core';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose';\nimport * as kinesis from '@aws-cdk/aws-kinesis';\nimport * as s3 from '@aws-cdk/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations';\nimport * as kms from '@aws-cdk/aws-kms';\nimport * as iam from '@aws-cdk/aws-iam';\nimport * as lambda from '@aws-cdk/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\n\n// SSE with an AWS-owned CMK\nnew firehose.DeliveryStream(this, 'Delivery Stream AWS Owned', {\n  encryption: firehose.StreamEncryption.AWS_OWNED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew firehose.DeliveryStream(this, 'Delivery Stream Implicit Customer Managed', {\n  encryption: firehose.StreamEncryption.CUSTOMER_MANAGED,\n  destinations: [destination],\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream Explicit Customer Managed', {\n  encryptionKey: key,\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 3,
        "75": 28,
        "104": 3,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 3,
        "193": 3,
        "194": 7,
        "197": 3,
        "225": 2,
        "226": 3,
        "242": 2,
        "243": 2,
        "281": 6,
        "290": 1
      },
      "fqnsFingerprint": "da059281618503eeb4254ca396607e6fcdbfa657e966b13ec5bec220a3eead1b"
    }
  }
}
